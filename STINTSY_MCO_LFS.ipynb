{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction ##\n",
    "\n",
    "In this notebook, the dataset to be processed is the Labor Force Survey conducted April 2016 and retrieved through Philippine Statistics Authority database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import ttest_rel\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing LFS PUF April 2016.CSV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lfs_data = pd.read_csv(\"src/data/LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Information, Pre-Processing, and Cleaning</h1>\n",
    "\n",
    "Let's get an overview of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180862 entries, 0 to 180861\n",
      "Data columns (total 50 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   PUFREG           180862 non-null  int64  \n",
      " 1   PUFPRV           180862 non-null  int64  \n",
      " 2   PUFPRRCD         180862 non-null  int64  \n",
      " 3   PUFHHNUM         180862 non-null  int64  \n",
      " 4   PUFURB2K10       180862 non-null  int64  \n",
      " 5   PUFPWGTFIN       180862 non-null  float64\n",
      " 6   PUFSVYMO         180862 non-null  int64  \n",
      " 7   PUFSVYYR         180862 non-null  int64  \n",
      " 8   PUFPSU           180862 non-null  int64  \n",
      " 9   PUFRPL           180862 non-null  int64  \n",
      " 10  PUFHHSIZE        180862 non-null  int64  \n",
      " 11  PUFC01_LNO       180862 non-null  int64  \n",
      " 12  PUFC03_REL       180862 non-null  int64  \n",
      " 13  PUFC04_SEX       180862 non-null  int64  \n",
      " 14  PUFC05_AGE       180862 non-null  int64  \n",
      " 15  PUFC06_MSTAT     180862 non-null  object \n",
      " 16  PUFC07_GRADE     180862 non-null  object \n",
      " 17  PUFC08_CURSCH    180862 non-null  object \n",
      " 18  PUFC09_GRADTECH  180862 non-null  object \n",
      " 19  PUFC10_CONWR     180862 non-null  object \n",
      " 20  PUFC11_WORK      180862 non-null  object \n",
      " 21  PUFC12_JOB       180862 non-null  object \n",
      " 22  PUFC14_PROCC     180862 non-null  object \n",
      " 23  PUFC16_PKB       180862 non-null  object \n",
      " 24  PUFC17_NATEM     180862 non-null  object \n",
      " 25  PUFC18_PNWHRS    180862 non-null  object \n",
      " 26  PUFC19_PHOURS    180862 non-null  object \n",
      " 27  PUFC20_PWMORE    180862 non-null  object \n",
      " 28  PUFC21_PLADDW    180862 non-null  object \n",
      " 29  PUFC22_PFWRK     180862 non-null  object \n",
      " 30  PUFC23_PCLASS    180862 non-null  object \n",
      " 31  PUFC24_PBASIS    180862 non-null  object \n",
      " 32  PUFC25_PBASIC    180862 non-null  object \n",
      " 33  PUFC26_OJOB      180862 non-null  object \n",
      " 34  PUFC27_NJOBS     180862 non-null  object \n",
      " 35  PUFC28_THOURS    180862 non-null  object \n",
      " 36  PUFC29_WWM48H    180862 non-null  object \n",
      " 37  PUFC30_LOOKW     180862 non-null  object \n",
      " 38  PUFC31_FLWRK     180862 non-null  object \n",
      " 39  PUFC32_JOBSM     180862 non-null  object \n",
      " 40  PUFC33_WEEKS     180862 non-null  object \n",
      " 41  PUFC34_WYNOT     180862 non-null  object \n",
      " 42  PUFC35_LTLOOKW   180862 non-null  object \n",
      " 43  PUFC36_AVAIL     180862 non-null  object \n",
      " 44  PUFC37_WILLING   180862 non-null  object \n",
      " 45  PUFC38_PREVJOB   180862 non-null  object \n",
      " 46  PUFC40_POCC      180862 non-null  object \n",
      " 47  PUFC41_WQTR      180862 non-null  object \n",
      " 48  PUFC43_QKB       180862 non-null  object \n",
      " 49  PUFNEWEMPSTAT    180862 non-null  object \n",
      "dtypes: float64(1), int64(14), object(35)\n",
      "memory usage: 69.0+ MB\n"
     ]
    }
   ],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Of interest to us, there are:\n",
    "<ul><li>1 contains float values, </li>\n",
    "<li>14 contain integer values, and </li>\n",
    "<li><b>35 are object values</b>.</li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates here, and therefore no cleaning need follow in this regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to contain null values in the form of whitespaces. Let's count those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Empty Cells:\n",
      "PUFC06_MSTAT        18339\n",
      "PUFC07_GRADE        18339\n",
      "PUFC08_CURSCH      107137\n",
      "PUFC09_GRADTECH     57782\n",
      "PUFC10_CONWR        57782\n",
      "PUFC11_WORK         21894\n",
      "PUFC12_JOB          93306\n",
      "PUFC14_PROCC       108360\n",
      "PUFC16_PKB         108360\n",
      "PUFC17_NATEM       109507\n",
      "PUFC18_PNWHRS      109507\n",
      "PUFC19_PHOURS      109507\n",
      "PUFC20_PWMORE      109507\n",
      "PUFC21_PLADDW      109507\n",
      "PUFC22_PFWRK       109507\n",
      "PUFC23_PCLASS      109507\n",
      "PUFC24_PBASIS      138947\n",
      "PUFC25_PBASIC      144274\n",
      "PUFC26_OJOB        109507\n",
      "PUFC27_NJOBS       174924\n",
      "PUFC28_THOURS      109507\n",
      "PUFC29_WWM48H      163629\n",
      "PUFC30_LOOKW       132692\n",
      "PUFC31_FLWRK       178569\n",
      "PUFC32_JOBSM       178569\n",
      "PUFC33_WEEKS       178569\n",
      "PUFC34_WYNOT       134985\n",
      "PUFC35_LTLOOKW     179269\n",
      "PUFC36_AVAIL       174893\n",
      "PUFC37_WILLING     174893\n",
      "PUFC38_PREVJOB     132692\n",
      "PUFC40_POCC        152982\n",
      "PUFC41_WQTR         81627\n",
      "PUFC43_QKB         107825\n",
      "PUFNEWEMPSTAT       61337\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "has_null = lfs_data.apply(lambda col: col.str.isspace().sum() if col.dtype == 'object' else 0)\n",
    "\n",
    "print(\"Number Empty Cells:\")\n",
    "print(has_null[has_null > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And standardize, replacing these whitespace values with -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", -1, regex=True, inplace=True)\n",
    "nan_counts_per_column = lfs_data.isna().sum()\n",
    "print(nan_counts_per_column[nan_counts_per_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these are -1, let's return to the data types, and find if our object columns from earlier are convertible to integers (or float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safely convertable to int:\n",
      "['PUFC06_MSTAT', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC09_GRADTECH', 'PUFC10_CONWR', 'PUFC11_WORK', 'PUFC12_JOB', 'PUFC14_PROCC', 'PUFC16_PKB', 'PUFC17_NATEM', 'PUFC18_PNWHRS', 'PUFC19_PHOURS', 'PUFC20_PWMORE', 'PUFC21_PLADDW', 'PUFC22_PFWRK', 'PUFC23_PCLASS', 'PUFC24_PBASIS', 'PUFC25_PBASIC', 'PUFC26_OJOB', 'PUFC27_NJOBS', 'PUFC28_THOURS', 'PUFC29_WWM48H', 'PUFC30_LOOKW', 'PUFC31_FLWRK', 'PUFC32_JOBSM', 'PUFC33_WEEKS', 'PUFC34_WYNOT', 'PUFC35_LTLOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING', 'PUFC38_PREVJOB', 'PUFC40_POCC', 'PUFC41_WQTR', 'PUFC43_QKB', 'PUFNEWEMPSTAT']\n"
     ]
    }
   ],
   "source": [
    "int_convertible_columns = []\n",
    "\n",
    "for col in lfs_data.columns:\n",
    "    if lfs_data[col].dtypes == 'object':  \n",
    "        try:\n",
    "            float_vals = lfs_data[col].dropna().astype(float)\n",
    "            if (float_vals % 1 == 0).all():\n",
    "                int_convertible_columns.append(col)\n",
    "        except ValueError:\n",
    "            pass \n",
    "\n",
    "print(\"Safely convertable to int:\")\n",
    "print(int_convertible_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And convert to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'PUFC06_MSTAT', 'PUFC08_CURSCH', 'PUFC09_GRADTECH', 'PUFC10_CONWR', 'PUFC11_WORK', \n",
    "    'PUFC12_JOB', 'PUFC14_PROCC', 'PUFC16_PKB', 'PUFC17_NATEM', 'PUFC18_PNWHRS', \n",
    "    'PUFC19_PHOURS', 'PUFC20_PWMORE', 'PUFC21_PLADDW', 'PUFC22_PFWRK', 'PUFC23_PCLASS', \n",
    "    'PUFC24_PBASIS', 'PUFC25_PBASIC', 'PUFC26_OJOB', 'PUFC27_NJOBS', 'PUFC28_THOURS', \n",
    "    'PUFC29_WWM48H', 'PUFC30_LOOKW', 'PUFC31_FLWRK', 'PUFC32_JOBSM', 'PUFC33_WEEKS', \n",
    "    'PUFC34_WYNOT', 'PUFC35_LTLOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING', 'PUFC38_PREVJOB', \n",
    "    'PUFC40_POCC', 'PUFC41_WQTR', 'PUFC43_QKB', 'PUFNEWEMPSTAT'\n",
    "]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    lfs_data[col] = lfs_data[col].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's also apply the unique() function to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUFREG                17\n",
       "PUFPRV                86\n",
       "PUFPRRCD             116\n",
       "PUFHHNUM           40880\n",
       "PUFURB2K10             2\n",
       "PUFPWGTFIN         35599\n",
       "PUFSVYMO               1\n",
       "PUFSVYYR               1\n",
       "PUFPSU               975\n",
       "PUFRPL                 4\n",
       "PUFHHSIZE             20\n",
       "PUFC01_LNO            23\n",
       "PUFC03_REL            11\n",
       "PUFC04_SEX             2\n",
       "PUFC05_AGE           100\n",
       "PUFC06_MSTAT           7\n",
       "PUFC07_GRADE          68\n",
       "PUFC08_CURSCH          3\n",
       "PUFC09_GRADTECH        3\n",
       "PUFC10_CONWR           6\n",
       "PUFC11_WORK            3\n",
       "PUFC12_JOB             3\n",
       "PUFC14_PROCC          44\n",
       "PUFC16_PKB            88\n",
       "PUFC17_NATEM           4\n",
       "PUFC18_PNWHRS         17\n",
       "PUFC19_PHOURS        103\n",
       "PUFC20_PWMORE          3\n",
       "PUFC21_PLADDW          3\n",
       "PUFC22_PFWRK           3\n",
       "PUFC23_PCLASS          8\n",
       "PUFC24_PBASIS          9\n",
       "PUFC25_PBASIC       1152\n",
       "PUFC26_OJOB            3\n",
       "PUFC27_NJOBS           6\n",
       "PUFC28_THOURS        111\n",
       "PUFC29_WWM48H          6\n",
       "PUFC30_LOOKW           3\n",
       "PUFC31_FLWRK           3\n",
       "PUFC32_JOBSM           7\n",
       "PUFC33_WEEKS          36\n",
       "PUFC34_WYNOT          10\n",
       "PUFC35_LTLOOKW         4\n",
       "PUFC36_AVAIL           3\n",
       "PUFC37_WILLING         3\n",
       "PUFC38_PREVJOB         3\n",
       "PUFC40_POCC           44\n",
       "PUFC41_WQTR            3\n",
       "PUFC43_QKB            89\n",
       "PUFNEWEMPSTAT          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Considering our dataset has 18,000 entries, features with particularly low numbers stand out as questions that have clear, defined choices. Reviewing the [questionnaire](https://psada.psa.gov.ph/catalog/67/download/537), we find that certain questions ask the participant to specify beyond prespecified choices.\n",
    "\n",
    "This column possibly contains \"010,\" which is obviously not an integer. We ensure this column is a string, and check for values not specified in the questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['350' '320' '250' -1 '622' '672' '240' '220' '614' '330' '010' '280'\n",
      " '632' '310' '000' '900' '820' '230' '589' '572' '210' '830' '810' '634'\n",
      " '686' '581' '681' '552' '534' '840' '658' '548' '648' '652' '662' '601'\n",
      " '642' '562' '260' '685' '631' '684' '340' '584' '621' '410' '420' '664'\n",
      " '676' '521' '638' '554' '646' '689' '522' '654' '644' '532' '531' '514'\n",
      " '558' '501' '586' '542' '576' '544' '585' '564']\n"
     ]
    }
   ],
   "source": [
    "lfs_data['PUFC07_GRADE'] = lfs_data['PUFC07_GRADE']\n",
    "valid_codes = [\n",
    "    0, 10,  # No Grade, Preschool\n",
    "    210, 220, 230, 240, 250, 260, 280,  # Elementary\n",
    "    310, 320, 330, 340, 350,  # High School\n",
    "    410, 420,  # Post Secondary; If Graduate Specify\n",
    "    810, 820, 830, 840,  # College; If Graduate Specify\n",
    "    900,  # Post Baccalaureate\n",
    "    np.nan\n",
    "]\n",
    "invalid_rows = lfs_data[~(lfs_data['PUFC07_GRADE'].isin(valid_codes))]\n",
    "\n",
    "unique_invalid_values = invalid_rows['PUFC07_GRADE'].unique()\n",
    "print(unique_invalid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values 5XX 6XX are not detailed in the questionnaire. As it instructs the participant to specify whether they graduated from post secondary or college, we'll create a new data point to encapsulate these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\n"
     ]
    }
   ],
   "source": [
    "lfs_data.loc[~lfs_data['PUFC07_GRADE'].isin(valid_codes), 'PUFC07_GRADE'] = 700\n",
    "print(lfs_data['PUFC07_GRADE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUFC11_WORK\n",
       " 2    87556\n",
       " 1    71412\n",
       "-1    21894\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data['PUFC11_WORK'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong correlations (|corr| > 0.5 and |corr| < 1):\n",
      "PUFPRV — PUFPRRCD: 1.000\n",
      "PUFREG — PUFHHNUM: 0.995\n",
      "PUFC19_PHOURS — PUFC28_THOURS: 0.972\n",
      "PUFC16_PKB — PUFC43_QKB: 0.969\n",
      "PUFC11_WORK — PUFNEWEMPSTAT: 0.964\n",
      "PUFC41_WQTR — PUFNEWEMPSTAT: 0.878\n",
      "PUFC11_WORK — PUFC41_WQTR: 0.852\n",
      "PUFC31_FLWRK — PUFC38_PREVJOB: -0.795\n",
      "PUFC36_AVAIL — PUFC37_WILLING: 0.785\n",
      "PUFC37_WILLING — PUFNEWEMPSTAT: 0.785\n",
      "PUFC18_PNWHRS — PUFC19_PHOURS: 0.785\n",
      "PUFC18_PNWHRS — PUFC28_THOURS: 0.769\n",
      "PUFPWGTFIN — PUFPSU: 0.709\n",
      "PUFC12_JOB — PUFNEWEMPSTAT: 0.704\n",
      "PUFC05_AGE — PUFC06_MSTAT: 0.701\n",
      "PUFC34_WYNOT — PUFNEWEMPSTAT: 0.631\n",
      "PUFC30_LOOKW — PUFNEWEMPSTAT: 0.625\n",
      "PUFC01_LNO — PUFC03_REL: 0.625\n",
      "PUFC05_AGE — PUFC08_CURSCH: 0.590\n",
      "PUFHHSIZE — PUFC01_LNO: 0.571\n",
      "PUFC01_LNO — PUFC05_AGE: -0.567\n",
      "PUFC20_PWMORE — PUFC21_PLADDW: 0.556\n",
      "PUFC08_CURSCH — PUFC11_WORK: -0.514\n",
      "PUFC08_CURSCH — PUFC34_WYNOT: -0.510\n",
      "PUFC08_CURSCH — PUFNEWEMPSTAT: -0.509\n"
     ]
    }
   ],
   "source": [
    "lfs_data_with_nan = lfs_data.copy()\n",
    "lfs_data_with_nan.replace(-1, np.nan, inplace=True)\n",
    "corr_matrix = lfs_data_with_nan.corr()\n",
    "\n",
    "strong_correlations = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)): \n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if (0.5 < corr_value < 1) or (-1 < corr_value < -0.5):\n",
    "            strong_correlations.append((\n",
    "                corr_matrix.index[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_value\n",
    "            ))\n",
    "\n",
    "strong_correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(\"Strong correlations (|corr| > 0.5 and |corr| < 1):\")\n",
    "for var1, var2, corr in strong_correlations:\n",
    "    print(f\"{var1} — {var2}: {corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use feature_cols as our predictor variables for PUFC11_WORK. Using Regression, we will evaluate how well we can predict whether or not someone has worked in the past week. We begin with preprocessing.\n",
    "\n",
    "### Logistic Regression (LR)\n",
    "Because this is a classification task, we can choose Logistic Regression as a baseline and a first model. In theory, PUFC11_WORK is a binary classification task, something that Logistic Regression should excel at. Since this uses a sigmoid function to map linear probabilities, between 0 and 1, making this suitable for determining whether someone \"worked\" (1) or \"did not work\" (0) within the past week. Finally, LR is particularly interpetable considering the task we're doing, allowing us to check the significance and coefficients associated with each predictor variable if need be.\n",
    "\n",
    "#### Preprocessing: LR\n",
    "We create a copy of our target variable PUFC11_WORK, and create five 80-20 train-test splits for the non-empty PUFC11 data we have. We'll also perform one-hot encoding, given our feature columns are all categorical. We also map the values of PUFC11, normally [1,2], to [0,1]. In addition, because we've determined that our feature_cols are intentionally unanswered as appropriate, we will be treating these values as empty rather than imputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for k-fold cross-validation...\n",
      "Training on 127174 samples with 9 features\n",
      "Testing on 31794 samples\n",
      "Features: ['PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC38_PREVJOB', 'PUFC31_FLWRK', 'PUFC30_LOOKW', 'PUFC34_WYNOT']\n",
      "Training on 127174 samples with 9 features\n",
      "Testing on 31794 samples\n",
      "Features: ['PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC38_PREVJOB', 'PUFC31_FLWRK', 'PUFC30_LOOKW', 'PUFC34_WYNOT']\n",
      "Training on 127174 samples with 9 features\n",
      "Testing on 31794 samples\n",
      "Features: ['PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC38_PREVJOB', 'PUFC31_FLWRK', 'PUFC30_LOOKW', 'PUFC34_WYNOT']\n",
      "Training on 127175 samples with 9 features\n",
      "Testing on 31793 samples\n",
      "Features: ['PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC38_PREVJOB', 'PUFC31_FLWRK', 'PUFC30_LOOKW', 'PUFC34_WYNOT']\n",
      "Training on 127175 samples with 9 features\n",
      "Testing on 31793 samples\n",
      "Features: ['PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC08_CURSCH', 'PUFC38_PREVJOB', 'PUFC31_FLWRK', 'PUFC30_LOOKW', 'PUFC34_WYNOT']\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing import prepare_data_kfold\n",
    "\n",
    "target_col = 'PUFC11_WORK'\n",
    "feature_cols = [\n",
    "    'PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', \n",
    "    'PUFC07_GRADE', 'PUFC08_CURSCH', \n",
    "    'PUFC38_PREVJOB', 'PUFC31_FLWRK',\n",
    "    'PUFC30_LOOKW', 'PUFC34_WYNOT'\n",
    "]\n",
    "\n",
    "categorical_cols = feature_cols\n",
    "n_splits = 5\n",
    "missing_value =-1\n",
    "seed = 45\n",
    "\n",
    "folds_data = prepare_data_kfold(lfs_data, target_col = target_col,\n",
    "                         n_splits = n_splits,\n",
    "                         missing_value = missing_value,\n",
    "                         categorical_cols = categorical_cols,\n",
    "                         feature_cols = feature_cols,\n",
    "                         seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training: LR\n",
    "We are ready to start training. As we are setting a baseline, we'll start off with these hyperparameters. We'll use Stochastic Gradient Descent as our specified optimizer, though technically implementing mini-batch with a batch size of 128. We are looking for improvements in loss greater than 0.0001, else we stop early within three epochs. Lastly, we use a weight_decay of 0, indicating no regularization for now. All hyperparameters indicated below also indicate their default value if unspecified. For each convergence, we will track the metrics of that fold and aggregate it across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== FOLD 1 ====================\n",
      "Epoch 1/50: Train Loss: 0.4103, Test Loss: 0.2856, Train Acc: 0.9367, Test Acc: 0.9579, LR: 0.010000\n",
      "Epoch 2/50: Train Loss: 0.2446, Test Loss: 0.2140, Train Acc: 0.9606, Test Acc: 0.9622, LR: 0.010000\n",
      "Epoch 3/50: Train Loss: 0.1981, Test Loss: 0.1835, Train Acc: 0.9588, Test Acc: 0.9596, LR: 0.010000\n",
      "Epoch 4/50: Train Loss: 0.1755, Test Loss: 0.1665, Train Acc: 0.9566, Test Acc: 0.9561, LR: 0.010000\n",
      "Epoch 5/50: Train Loss: 0.1620, Test Loss: 0.1557, Train Acc: 0.9549, Test Acc: 0.9570, LR: 0.005000\n",
      "Epoch 6/50: Train Loss: 0.1550, Test Loss: 0.1516, Train Acc: 0.9557, Test Acc: 0.9578, LR: 0.005000\n",
      "Epoch 7/50: Train Loss: 0.1513, Test Loss: 0.1482, Train Acc: 0.9564, Test Acc: 0.9581, LR: 0.005000\n",
      "Epoch 8/50: Train Loss: 0.1482, Test Loss: 0.1452, Train Acc: 0.9565, Test Acc: 0.9581, LR: 0.005000\n",
      "Epoch 9/50: Train Loss: 0.1454, Test Loss: 0.1427, Train Acc: 0.9565, Test Acc: 0.9581, LR: 0.005000\n",
      "Epoch 10/50: Train Loss: 0.1430, Test Loss: 0.1404, Train Acc: 0.9565, Test Acc: 0.9581, LR: 0.002500\n",
      "Epoch 11/50: Train Loss: 0.1414, Test Loss: 0.1394, Train Acc: 0.9565, Test Acc: 0.9581, LR: 0.002500\n",
      "Epoch 12/50: Train Loss: 0.1405, Test Loss: 0.1384, Train Acc: 0.9566, Test Acc: 0.9581, LR: 0.002500\n",
      "Epoch 13/50: Train Loss: 0.1395, Test Loss: 0.1375, Train Acc: 0.9566, Test Acc: 0.9581, LR: 0.002500\n",
      "Epoch 14/50: Train Loss: 0.1386, Test Loss: 0.1366, Train Acc: 0.9566, Test Acc: 0.9581, LR: 0.002500\n",
      "Epoch 15/50: Train Loss: 0.1377, Test Loss: 0.1357, Train Acc: 0.9566, Test Acc: 0.9581, LR: 0.001250\n",
      "Epoch 16/50: Train Loss: 0.1371, Test Loss: 0.1353, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.001250\n",
      "Epoch 17/50: Train Loss: 0.1367, Test Loss: 0.1349, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.001250\n",
      "Epoch 18/50: Train Loss: 0.1363, Test Loss: 0.1346, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.001250\n",
      "Epoch 19/50: Train Loss: 0.1359, Test Loss: 0.1342, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.001250\n",
      "Epoch 20/50: Train Loss: 0.1355, Test Loss: 0.1338, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000625\n",
      "Epoch 21/50: Train Loss: 0.1353, Test Loss: 0.1336, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000625\n",
      "Epoch 22/50: Train Loss: 0.1351, Test Loss: 0.1335, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000625\n",
      "Epoch 23/50: Train Loss: 0.1349, Test Loss: 0.1333, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000625\n",
      "Epoch 24/50: Train Loss: 0.1348, Test Loss: 0.1331, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000625\n",
      "Epoch 25/50: Train Loss: 0.1346, Test Loss: 0.1329, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000313\n",
      "Epoch 26/50: Train Loss: 0.1344, Test Loss: 0.1328, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000313\n",
      "Epoch 27/50: Train Loss: 0.1344, Test Loss: 0.1328, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000313\n",
      "Epoch 28/50: Train Loss: 0.1343, Test Loss: 0.1327, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000313\n",
      "Epoch 29/50: Train Loss: 0.1342, Test Loss: 0.1326, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000313\n",
      "Epoch 30/50: Train Loss: 0.1341, Test Loss: 0.1325, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000156\n",
      "Epoch 31/50: Train Loss: 0.1340, Test Loss: 0.1325, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000156\n",
      "Epoch 32/50: Train Loss: 0.1340, Test Loss: 0.1324, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000156\n",
      "Epoch 33/50: Train Loss: 0.1340, Test Loss: 0.1324, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000156\n",
      "Epoch 34/50: Train Loss: 0.1340, Test Loss: 0.1323, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000156\n",
      "Epoch 35/50: Train Loss: 0.1339, Test Loss: 0.1323, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000078\n",
      "Epoch 36/50: Train Loss: 0.1339, Test Loss: 0.1323, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000078\n",
      "Epoch 37/50: Train Loss: 0.1339, Test Loss: 0.1322, Train Acc: 0.9567, Test Acc: 0.9581, LR: 0.000078\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13701   601]\n",
      " [  730 16762]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94941445 0.95797791 0.95367696     14302\n",
      "         1.0  0.96538617 0.95826664 0.96181323     17492\n",
      "\n",
      "    accuracy                      0.95813676     31794\n",
      "   macro avg  0.95740031 0.95812227 0.95774509     31794\n",
      "weighted avg  0.95820156 0.95813676 0.95815326     31794\n",
      "\n",
      "\n",
      "==================== FOLD 2 ====================\n",
      "Epoch 1/50: Train Loss: 0.4101, Test Loss: 0.2856, Train Acc: 0.9387, Test Acc: 0.9581, LR: 0.010000\n",
      "Epoch 2/50: Train Loss: 0.2442, Test Loss: 0.2145, Train Acc: 0.9605, Test Acc: 0.9601, LR: 0.010000\n",
      "Epoch 3/50: Train Loss: 0.1976, Test Loss: 0.1842, Train Acc: 0.9589, Test Acc: 0.9584, LR: 0.010000\n",
      "Epoch 4/50: Train Loss: 0.1750, Test Loss: 0.1674, Train Acc: 0.9562, Test Acc: 0.9551, LR: 0.010000\n",
      "Epoch 5/50: Train Loss: 0.1616, Test Loss: 0.1568, Train Acc: 0.9552, Test Acc: 0.9558, LR: 0.005000\n",
      "Epoch 6/50: Train Loss: 0.1545, Test Loss: 0.1528, Train Acc: 0.9560, Test Acc: 0.9565, LR: 0.005000\n",
      "Epoch 7/50: Train Loss: 0.1508, Test Loss: 0.1494, Train Acc: 0.9566, Test Acc: 0.9570, LR: 0.005000\n",
      "Epoch 8/50: Train Loss: 0.1476, Test Loss: 0.1465, Train Acc: 0.9567, Test Acc: 0.9570, LR: 0.005000\n",
      "Epoch 9/50: Train Loss: 0.1449, Test Loss: 0.1440, Train Acc: 0.9568, Test Acc: 0.9571, LR: 0.005000\n",
      "Epoch 10/50: Train Loss: 0.1425, Test Loss: 0.1418, Train Acc: 0.9568, Test Acc: 0.9571, LR: 0.002500\n",
      "Epoch 11/50: Train Loss: 0.1409, Test Loss: 0.1408, Train Acc: 0.9568, Test Acc: 0.9571, LR: 0.002500\n",
      "Epoch 12/50: Train Loss: 0.1399, Test Loss: 0.1398, Train Acc: 0.9568, Test Acc: 0.9571, LR: 0.002500\n",
      "Epoch 13/50: Train Loss: 0.1389, Test Loss: 0.1389, Train Acc: 0.9568, Test Acc: 0.9571, LR: 0.002500\n",
      "Epoch 14/50: Train Loss: 0.1380, Test Loss: 0.1380, Train Acc: 0.9568, Test Acc: 0.9572, LR: 0.002500\n",
      "Epoch 15/50: Train Loss: 0.1372, Test Loss: 0.1372, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.001250\n",
      "Epoch 16/50: Train Loss: 0.1366, Test Loss: 0.1368, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.001250\n",
      "Epoch 17/50: Train Loss: 0.1362, Test Loss: 0.1364, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.001250\n",
      "Epoch 18/50: Train Loss: 0.1357, Test Loss: 0.1361, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.001250\n",
      "Epoch 19/50: Train Loss: 0.1354, Test Loss: 0.1357, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.001250\n",
      "Epoch 20/50: Train Loss: 0.1350, Test Loss: 0.1353, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000625\n",
      "Epoch 21/50: Train Loss: 0.1348, Test Loss: 0.1351, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000625\n",
      "Epoch 22/50: Train Loss: 0.1346, Test Loss: 0.1350, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000625\n",
      "Epoch 23/50: Train Loss: 0.1344, Test Loss: 0.1348, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000625\n",
      "Epoch 24/50: Train Loss: 0.1342, Test Loss: 0.1346, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000625\n",
      "Epoch 25/50: Train Loss: 0.1341, Test Loss: 0.1344, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000313\n",
      "Epoch 26/50: Train Loss: 0.1339, Test Loss: 0.1344, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000313\n",
      "Epoch 27/50: Train Loss: 0.1338, Test Loss: 0.1343, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000313\n",
      "Epoch 28/50: Train Loss: 0.1337, Test Loss: 0.1342, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000313\n",
      "Epoch 29/50: Train Loss: 0.1337, Test Loss: 0.1341, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000313\n",
      "Epoch 30/50: Train Loss: 0.1335, Test Loss: 0.1340, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000156\n",
      "Epoch 31/50: Train Loss: 0.1335, Test Loss: 0.1340, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000156\n",
      "Epoch 32/50: Train Loss: 0.1335, Test Loss: 0.1339, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000156\n",
      "Epoch 33/50: Train Loss: 0.1334, Test Loss: 0.1339, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000156\n",
      "Epoch 34/50: Train Loss: 0.1334, Test Loss: 0.1339, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000156\n",
      "Epoch 35/50: Train Loss: 0.1334, Test Loss: 0.1338, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000078\n",
      "Epoch 36/50: Train Loss: 0.1333, Test Loss: 0.1338, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000078\n",
      "Epoch 37/50: Train Loss: 0.1333, Test Loss: 0.1338, Train Acc: 0.9569, Test Acc: 0.9572, LR: 0.000078\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13592   594]\n",
      " [  766 16842]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94664995 0.95812773 0.95235426     14186\n",
      "         1.0  0.96593255 0.95649705 0.96119164     17608\n",
      "\n",
      "    accuracy                      0.95722463     31794\n",
      "   macro avg  0.95629125 0.95731239 0.95677295     31794\n",
      "weighted avg  0.95732895 0.95722463 0.95724854     31794\n",
      "\n",
      "\n",
      "==================== FOLD 3 ====================\n",
      "Epoch 1/50: Train Loss: 0.4098, Test Loss: 0.2869, Train Acc: 0.9389, Test Acc: 0.9579, LR: 0.010000\n",
      "Epoch 2/50: Train Loss: 0.2442, Test Loss: 0.2153, Train Acc: 0.9604, Test Acc: 0.9600, LR: 0.010000\n",
      "Epoch 3/50: Train Loss: 0.1978, Test Loss: 0.1847, Train Acc: 0.9588, Test Acc: 0.9587, LR: 0.010000\n",
      "Epoch 4/50: Train Loss: 0.1752, Test Loss: 0.1677, Train Acc: 0.9563, Test Acc: 0.9553, LR: 0.010000\n",
      "Epoch 5/50: Train Loss: 0.1618, Test Loss: 0.1570, Train Acc: 0.9551, Test Acc: 0.9558, LR: 0.005000\n",
      "Epoch 6/50: Train Loss: 0.1547, Test Loss: 0.1529, Train Acc: 0.9559, Test Acc: 0.9563, LR: 0.005000\n",
      "Epoch 7/50: Train Loss: 0.1510, Test Loss: 0.1495, Train Acc: 0.9566, Test Acc: 0.9567, LR: 0.005000\n",
      "Epoch 8/50: Train Loss: 0.1479, Test Loss: 0.1465, Train Acc: 0.9568, Test Acc: 0.9568, LR: 0.005000\n",
      "Epoch 9/50: Train Loss: 0.1452, Test Loss: 0.1440, Train Acc: 0.9568, Test Acc: 0.9568, LR: 0.005000\n",
      "Epoch 10/50: Train Loss: 0.1428, Test Loss: 0.1417, Train Acc: 0.9568, Test Acc: 0.9568, LR: 0.002500\n",
      "Epoch 11/50: Train Loss: 0.1412, Test Loss: 0.1407, Train Acc: 0.9569, Test Acc: 0.9568, LR: 0.002500\n",
      "Epoch 12/50: Train Loss: 0.1401, Test Loss: 0.1397, Train Acc: 0.9569, Test Acc: 0.9568, LR: 0.002500\n",
      "Epoch 13/50: Train Loss: 0.1392, Test Loss: 0.1388, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.002500\n",
      "Epoch 14/50: Train Loss: 0.1383, Test Loss: 0.1379, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.002500\n",
      "Epoch 15/50: Train Loss: 0.1375, Test Loss: 0.1370, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.001250\n",
      "Epoch 16/50: Train Loss: 0.1369, Test Loss: 0.1366, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.001250\n",
      "Epoch 17/50: Train Loss: 0.1364, Test Loss: 0.1362, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.001250\n",
      "Epoch 18/50: Train Loss: 0.1361, Test Loss: 0.1358, Train Acc: 0.9569, Test Acc: 0.9569, LR: 0.001250\n",
      "Epoch 19/50: Train Loss: 0.1358, Test Loss: 0.1355, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.001250\n",
      "Epoch 20/50: Train Loss: 0.1353, Test Loss: 0.1351, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000625\n",
      "Epoch 21/50: Train Loss: 0.1351, Test Loss: 0.1349, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000625\n",
      "Epoch 22/50: Train Loss: 0.1349, Test Loss: 0.1347, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000625\n",
      "Epoch 23/50: Train Loss: 0.1347, Test Loss: 0.1346, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000625\n",
      "Epoch 24/50: Train Loss: 0.1346, Test Loss: 0.1344, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000625\n",
      "Epoch 25/50: Train Loss: 0.1344, Test Loss: 0.1342, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000313\n",
      "Epoch 26/50: Train Loss: 0.1343, Test Loss: 0.1341, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000313\n",
      "Epoch 27/50: Train Loss: 0.1341, Test Loss: 0.1340, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000313\n",
      "Epoch 28/50: Train Loss: 0.1341, Test Loss: 0.1339, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000313\n",
      "Epoch 29/50: Train Loss: 0.1340, Test Loss: 0.1339, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000313\n",
      "Epoch 30/50: Train Loss: 0.1339, Test Loss: 0.1338, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000156\n",
      "Epoch 31/50: Train Loss: 0.1338, Test Loss: 0.1337, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000156\n",
      "Epoch 32/50: Train Loss: 0.1338, Test Loss: 0.1337, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000156\n",
      "Epoch 33/50: Train Loss: 0.1337, Test Loss: 0.1336, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000156\n",
      "Epoch 34/50: Train Loss: 0.1337, Test Loss: 0.1336, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000156\n",
      "Epoch 35/50: Train Loss: 0.1337, Test Loss: 0.1336, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000078\n",
      "Epoch 36/50: Train Loss: 0.1336, Test Loss: 0.1335, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000078\n",
      "Epoch 37/50: Train Loss: 0.1336, Test Loss: 0.1335, Train Acc: 0.9570, Test Acc: 0.9569, LR: 0.000078\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13750   599]\n",
      " [  770 16675]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94696970 0.95825493 0.95257889     14349\n",
      "         1.0  0.96532361 0.95586128 0.96056914     17445\n",
      "\n",
      "    accuracy                      0.95694156     31794\n",
      "   macro avg  0.95614665 0.95705810 0.95657402     31794\n",
      "weighted avg  0.95704028 0.95694156 0.95696305     31794\n",
      "\n",
      "\n",
      "==================== FOLD 4 ====================\n",
      "Epoch 1/50: Train Loss: 0.4106, Test Loss: 0.2845, Train Acc: 0.9408, Test Acc: 0.9586, LR: 0.010000\n",
      "Epoch 2/50: Train Loss: 0.2447, Test Loss: 0.2130, Train Acc: 0.9606, Test Acc: 0.9619, LR: 0.010000\n",
      "Epoch 3/50: Train Loss: 0.1981, Test Loss: 0.1827, Train Acc: 0.9589, Test Acc: 0.9580, LR: 0.010000\n",
      "Epoch 4/50: Train Loss: 0.1754, Test Loss: 0.1658, Train Acc: 0.9557, Test Acc: 0.9547, LR: 0.010000\n",
      "Epoch 5/50: Train Loss: 0.1620, Test Loss: 0.1552, Train Acc: 0.9552, Test Acc: 0.9555, LR: 0.005000\n",
      "Epoch 6/50: Train Loss: 0.1549, Test Loss: 0.1512, Train Acc: 0.9560, Test Acc: 0.9559, LR: 0.005000\n",
      "Epoch 7/50: Train Loss: 0.1512, Test Loss: 0.1478, Train Acc: 0.9566, Test Acc: 0.9565, LR: 0.005000\n",
      "Epoch 8/50: Train Loss: 0.1481, Test Loss: 0.1449, Train Acc: 0.9569, Test Acc: 0.9565, LR: 0.005000\n",
      "Epoch 9/50: Train Loss: 0.1454, Test Loss: 0.1424, Train Acc: 0.9569, Test Acc: 0.9565, LR: 0.005000\n",
      "Epoch 10/50: Train Loss: 0.1429, Test Loss: 0.1402, Train Acc: 0.9569, Test Acc: 0.9565, LR: 0.002500\n",
      "Epoch 11/50: Train Loss: 0.1413, Test Loss: 0.1391, Train Acc: 0.9569, Test Acc: 0.9565, LR: 0.002500\n",
      "Epoch 12/50: Train Loss: 0.1403, Test Loss: 0.1382, Train Acc: 0.9569, Test Acc: 0.9565, LR: 0.002500\n",
      "Epoch 13/50: Train Loss: 0.1394, Test Loss: 0.1373, Train Acc: 0.9570, Test Acc: 0.9565, LR: 0.002500\n",
      "Epoch 14/50: Train Loss: 0.1385, Test Loss: 0.1364, Train Acc: 0.9570, Test Acc: 0.9565, LR: 0.002500\n",
      "Epoch 15/50: Train Loss: 0.1377, Test Loss: 0.1356, Train Acc: 0.9570, Test Acc: 0.9566, LR: 0.001250\n",
      "Epoch 16/50: Train Loss: 0.1370, Test Loss: 0.1352, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.001250\n",
      "Epoch 17/50: Train Loss: 0.1366, Test Loss: 0.1348, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.001250\n",
      "Epoch 18/50: Train Loss: 0.1363, Test Loss: 0.1344, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.001250\n",
      "Epoch 19/50: Train Loss: 0.1359, Test Loss: 0.1340, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.001250\n",
      "Epoch 20/50: Train Loss: 0.1355, Test Loss: 0.1337, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000625\n",
      "Epoch 21/50: Train Loss: 0.1352, Test Loss: 0.1335, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000625\n",
      "Epoch 22/50: Train Loss: 0.1350, Test Loss: 0.1333, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000625\n",
      "Epoch 23/50: Train Loss: 0.1349, Test Loss: 0.1331, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000625\n",
      "Epoch 24/50: Train Loss: 0.1347, Test Loss: 0.1330, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000625\n",
      "Epoch 25/50: Train Loss: 0.1345, Test Loss: 0.1328, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000313\n",
      "Epoch 26/50: Train Loss: 0.1344, Test Loss: 0.1327, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000313\n",
      "Epoch 27/50: Train Loss: 0.1343, Test Loss: 0.1326, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000313\n",
      "Epoch 28/50: Train Loss: 0.1342, Test Loss: 0.1325, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000313\n",
      "Epoch 29/50: Train Loss: 0.1341, Test Loss: 0.1324, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000313\n",
      "Epoch 30/50: Train Loss: 0.1341, Test Loss: 0.1324, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000156\n",
      "Epoch 31/50: Train Loss: 0.1340, Test Loss: 0.1323, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000156\n",
      "Epoch 32/50: Train Loss: 0.1340, Test Loss: 0.1323, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000156\n",
      "Epoch 33/50: Train Loss: 0.1339, Test Loss: 0.1322, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000156\n",
      "Epoch 34/50: Train Loss: 0.1339, Test Loss: 0.1322, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000156\n",
      "Epoch 35/50: Train Loss: 0.1338, Test Loss: 0.1322, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000078\n",
      "Epoch 36/50: Train Loss: 0.1338, Test Loss: 0.1321, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000078\n",
      "Epoch 37/50: Train Loss: 0.1338, Test Loss: 0.1321, Train Acc: 0.9570, Test Acc: 0.9567, LR: 0.000078\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13622   591]\n",
      " [  787 16793]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94538136 0.95841835 0.95185522     14213\n",
      "         1.0  0.96600322 0.95523322 0.96058803     17580\n",
      "\n",
      "    accuracy                      0.95665713     31793\n",
      "   macro avg  0.95569229 0.95682578 0.95622162     31793\n",
      "weighted avg  0.95678426 0.95665713 0.95668404     31793\n",
      "\n",
      "\n",
      "==================== FOLD 5 ====================\n",
      "Epoch 1/50: Train Loss: 0.4097, Test Loss: 0.2874, Train Acc: 0.9391, Test Acc: 0.9562, LR: 0.010000\n",
      "Epoch 2/50: Train Loss: 0.2438, Test Loss: 0.2165, Train Acc: 0.9613, Test Acc: 0.9612, LR: 0.010000\n",
      "Epoch 3/50: Train Loss: 0.1972, Test Loss: 0.1862, Train Acc: 0.9591, Test Acc: 0.9570, LR: 0.010000\n",
      "Epoch 4/50: Train Loss: 0.1745, Test Loss: 0.1695, Train Acc: 0.9562, Test Acc: 0.9536, LR: 0.010000\n",
      "Epoch 5/50: Train Loss: 0.1611, Test Loss: 0.1589, Train Acc: 0.9554, Test Acc: 0.9541, LR: 0.005000\n",
      "Epoch 6/50: Train Loss: 0.1540, Test Loss: 0.1549, Train Acc: 0.9561, Test Acc: 0.9549, LR: 0.005000\n",
      "Epoch 7/50: Train Loss: 0.1504, Test Loss: 0.1515, Train Acc: 0.9567, Test Acc: 0.9556, LR: 0.005000\n",
      "Epoch 8/50: Train Loss: 0.1472, Test Loss: 0.1486, Train Acc: 0.9571, Test Acc: 0.9556, LR: 0.005000\n",
      "Epoch 9/50: Train Loss: 0.1445, Test Loss: 0.1461, Train Acc: 0.9571, Test Acc: 0.9556, LR: 0.005000\n",
      "Epoch 10/50: Train Loss: 0.1421, Test Loss: 0.1439, Train Acc: 0.9571, Test Acc: 0.9557, LR: 0.002500\n",
      "Epoch 11/50: Train Loss: 0.1405, Test Loss: 0.1429, Train Acc: 0.9571, Test Acc: 0.9557, LR: 0.002500\n",
      "Epoch 12/50: Train Loss: 0.1395, Test Loss: 0.1419, Train Acc: 0.9571, Test Acc: 0.9557, LR: 0.002500\n",
      "Epoch 13/50: Train Loss: 0.1385, Test Loss: 0.1410, Train Acc: 0.9571, Test Acc: 0.9557, LR: 0.002500\n",
      "Epoch 14/50: Train Loss: 0.1376, Test Loss: 0.1401, Train Acc: 0.9571, Test Acc: 0.9558, LR: 0.002500\n",
      "Epoch 15/50: Train Loss: 0.1368, Test Loss: 0.1393, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.001250\n",
      "Epoch 16/50: Train Loss: 0.1362, Test Loss: 0.1389, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.001250\n",
      "Epoch 17/50: Train Loss: 0.1358, Test Loss: 0.1385, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.001250\n",
      "Epoch 18/50: Train Loss: 0.1354, Test Loss: 0.1381, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.001250\n",
      "Epoch 19/50: Train Loss: 0.1351, Test Loss: 0.1378, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.001250\n",
      "Epoch 20/50: Train Loss: 0.1347, Test Loss: 0.1374, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000625\n",
      "Epoch 21/50: Train Loss: 0.1344, Test Loss: 0.1372, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000625\n",
      "Epoch 22/50: Train Loss: 0.1342, Test Loss: 0.1370, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000625\n",
      "Epoch 23/50: Train Loss: 0.1340, Test Loss: 0.1369, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000625\n",
      "Epoch 24/50: Train Loss: 0.1338, Test Loss: 0.1367, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000625\n",
      "Epoch 25/50: Train Loss: 0.1336, Test Loss: 0.1365, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000313\n",
      "Epoch 26/50: Train Loss: 0.1335, Test Loss: 0.1364, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000313\n",
      "Epoch 27/50: Train Loss: 0.1334, Test Loss: 0.1363, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000313\n",
      "Epoch 28/50: Train Loss: 0.1334, Test Loss: 0.1363, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000313\n",
      "Epoch 29/50: Train Loss: 0.1333, Test Loss: 0.1362, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000313\n",
      "Epoch 30/50: Train Loss: 0.1332, Test Loss: 0.1361, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000156\n",
      "Epoch 31/50: Train Loss: 0.1332, Test Loss: 0.1360, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000156\n",
      "Epoch 32/50: Train Loss: 0.1331, Test Loss: 0.1360, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000156\n",
      "Epoch 33/50: Train Loss: 0.1331, Test Loss: 0.1360, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000156\n",
      "Epoch 34/50: Train Loss: 0.1331, Test Loss: 0.1359, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000156\n",
      "Epoch 35/50: Train Loss: 0.1330, Test Loss: 0.1359, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000078\n",
      "Epoch 36/50: Train Loss: 0.1330, Test Loss: 0.1359, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000078\n",
      "Epoch 37/50: Train Loss: 0.1329, Test Loss: 0.1358, Train Acc: 0.9572, Test Acc: 0.9558, LR: 0.000078\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13762   600]\n",
      " [  805 16626]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94473811 0.95822309 0.95143282     14362\n",
      "         1.0  0.96516893 0.95381791 0.95945985     17431\n",
      "\n",
      "    accuracy                      0.95580788     31793\n",
      "   macro avg  0.95495352 0.95602050 0.95544633     31793\n",
      "weighted avg  0.95593962 0.95580788 0.95583376     31793\n",
      "\n",
      "==================== AGGREGATE RESULTS ====================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68427  2985]\n",
      " [ 3858 83698]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0  0.94662793 0.95820030 0.95237896     71412\n",
      "         1.0  0.96556418 0.95593677 0.96072636     87556\n",
      "\n",
      "    accuracy                      0.95695360    158968\n",
      "   macro avg  0.95609606 0.95706854 0.95655266    158968\n",
      "weighted avg  0.95705759 0.95695360 0.95697652    158968\n",
      "\n",
      "[0.9581367553626471, 0.9572246335786626, 0.9569415613008744, 0.9566571257824049, 0.9558078822382285]\n",
      "\n",
      "Model training complete!\n",
      "  Average Final Train Loss:     0.133485\n",
      "  Average Final Test Loss:      0.133499\n",
      "  Average Final Train Accuracy: 0.956954\n",
      "  Average Final Test Accuracy:  0.956954\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.trainEval import *\n",
    "result_dict = train_model(\n",
    "    folds_data,\n",
    "    optimizer_string=\"sgd\", #Stochastic Gradient Descent\n",
    "    scheduler_step_size=5,\n",
    "    learning_rate=0.01,\n",
    "    scheduler_gamma=0.5,\n",
    "    convergence_threshold=1e-4, \n",
    "    num_epochs=50,\n",
    "    patience=3, # Stop at 3 epochs with no improvement\n",
    "    weight_decay=0,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "lr_accuracies_test = result_dict[\"all_final_test_accuracies\"]\n",
    "print(lr_accuracies_test);\n",
    "\n",
    "\n",
    "print(\"\\nModel training complete!\")\n",
    "aggregate_cm = result_dict[\"aggregate_confusion_matrix\"]\n",
    "\n",
    "sns.heatmap(aggregate_cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"Negative\", \"Positive\"], \n",
    "            yticklabels=[\"Negative\", \"Positive\"]) \n",
    "\n",
    "\n",
    "print(f\"  Average Final Train Loss:     {result_dict['aggregated_final_metrics']['avg_final_train_loss']:.6f}\")\n",
    "print(f\"  Average Final Test Loss:      {result_dict['aggregated_final_metrics']['avg_final_test_loss']:.6f}\")\n",
    "print(f\"  Average Final Train Accuracy: {result_dict['aggregated_final_metrics']['avg_final_train_accuracy']:.6f}\")\n",
    "print(f\"  Average Final Test Accuracy:  {result_dict['aggregated_final_metrics']['avg_final_test_accuracy']:.6f}\")\n",
    "\n",
    "plt.title(\"Aggregate Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error: LR\n",
    "This model performed well for an initial run. All folds ran for 25 epochs. Both accuracies for test and train data are high, though there is usually minimal improvement from the third epoch onwards. The train and test loss both see steady improvement, but we see the test loss  to be slightly higher and plateau earlier at around the sixteenth epoch. \n",
    "\n",
    "We see that the train loss is slightly lower than the test loss in folds 1, 2, and 5, while the reverse is true for folds 3 and 4. This would indicate a model that overfits for the former folds, and underfits for the latter. Averaging these out, its clear that with an aggregated train and test loss of 0.684 and 0.687 respectively, the overall performance of the model doesn't significantly overfit nor underfit. This outcome is surprising, considering that we've used nine predictor variables while also forgoing the use of regularization, as these would have been expected to introduce noise and contribute to overfitting through curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our base parameters having been set, we can begin hyperparameter tuning. We'll implement *Random Search* as to not have to exhaustively branch through each possible combination of parameters. Below are the hyperparameter's we'll use and choose from. For example, if our algorithm randomly, for instance, chooses the second element of each, then it will test Logistic Regression at a learning rate of 0.1, batch size of 64, and the with the ADAM optimizer, etc. \n",
    "\n",
    "Values evenly spaced between 0.000001 and 0.001 will be explored for the learning rates. This will go on for fifty iterations, afterwhich a best model will be selected based on test accuracy. We'll perform random search rather than grid search, as a compromise to searching through all 259,200 combinations of hyperparameters in our grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configuration:\n",
      "{'weight_decay': np.float64(0.00046415888336127773), 'scheduler_step_size': 5, 'scheduler_gamma': 0.9, 'patience': 5, 'optimizer': 'sgd', 'num_epochs': 30, 'learning_rate': np.float64(0.06951927961775606), 'batch_size': 256}\n",
      "\n",
      "==================== FOLD 1 ====================\n",
      "Epoch 1/30: Train Loss: 0.1191, Test Loss: 0.0775, Train Acc: 0.9776, Test Acc: 0.9857, LR: 0.069519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m param_distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m     10\u001b[0m }\n\u001b[1;32m---> 12\u001b[0m hyperparameter_results \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_random_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolds_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32mc:\\Users\\Devon Javier\\OneDrive\\Desktop\\STINTSY\\INTSY PROJ\\src\\trainEval.py:198\u001b[0m, in \u001b[0;36mhyperparameter_random_search\u001b[1;34m(param_distributions, folds_data, n_iter_search)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     fold_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfolds_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_step_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscheduler_step_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_gamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscheduler_gamma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     avg_test_accuracy \u001b[38;5;241m=\u001b[39m fold_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_test_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    211\u001b[0m     avg_test_loss \u001b[38;5;241m=\u001b[39m fold_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_test_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Devon Javier\\OneDrive\\Desktop\\STINTSY\\INTSY PROJ\\src\\trainEval.py:125\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(folds_data, learning_rate, batch_size, num_epochs, scheduler_step_size, scheduler_gamma, missing_value, convergence_threshold, patience, weight_decay, optimizer_string, seed)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#converge criteria\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 125\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     test_loss, test_accuracy, all_y_test, all_predictions \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, criterion)\n\u001b[0;32m    127\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Devon Javier\\OneDrive\\Desktop\\STINTSY\\INTSY PROJ\\src\\trainEval.py:52\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     51\u001b[0m total_loss, correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m    170\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    171\u001b[0m         {\n\u001b[1;32m--> 172\u001b[0m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[0;32m    176\u001b[0m         }\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:285\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'learning_rate': np.logspace(-4, -1, 20),\n",
    "    'batch_size': [32, 64, 128, 256],\n",
    "    'optimizer': ['sgd', 'adam', 'rmsprop'],\n",
    "    'weight_decay': np.logspace(-5, -2, 10),\n",
    "    'num_epochs': [30, 50, 75, 100],\n",
    "    'scheduler_step_size': [5, 10, 15],\n",
    "    'scheduler_gamma': [0.5, 0.7, 0.9],\n",
    "    'patience': [3, 5, 7]\n",
    "}\n",
    "\n",
    "hyperparameter_results = hyperparameter_random_search(folds_data=folds_data, param_distributions=param_distributions, n_iter_search=50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPT Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##best_params = hyperparameter_results['best_params']\n",
    "##results_summary = hyperparameter_results['summary_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (DT)\n",
    "\n",
    "Another machine learning model we can use is the decision tree. Decision trees don't necessarily assume a linear relationship between our predictor variables and PUFC11, which could be benificial for finding complex relationships. Rather, they recursively partition our data with rules. Further, while it can get quite complex as it scales, individual nodes are also uncomplicated in how they are interpreted, which is also helpful for understanding the factors that determine whether an individual has worked within the past week.\n",
    "\n",
    "#### Training: DT\n",
    "We can recycle the one-hot encoded data we used in preparation for Logistic Regression and immediately use it for training our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.9852, Train Loss: 0.0702, Test Accuracy: 0.9847, Test Loss: 0.0724\n",
      "Fold 1 - Confusion Matrix:\n",
      "[[14020   282]\n",
      " [  206 17286]]\n",
      "\n",
      "Fold 2 - Train Accuracy: 0.9851, Train Loss: 0.0703, Test Accuracy: 0.9849, Test Loss: 0.0712\n",
      "Fold 2 - Confusion Matrix:\n",
      "[[13926   260]\n",
      " [  219 17389]]\n",
      "\n",
      "Fold 3 - Train Accuracy: 0.9850, Train Loss: 0.0706, Test Accuracy: 0.9854, Test Loss: 0.0747\n",
      "Fold 3 - Confusion Matrix:\n",
      "[[14106   243]\n",
      " [  222 17223]]\n",
      "\n",
      "Fold 4 - Train Accuracy: 0.9850, Train Loss: 0.0708, Test Accuracy: 0.9855, Test Loss: 0.0727\n",
      "Fold 4 - Confusion Matrix:\n",
      "[[13951   262]\n",
      " [  200 17380]]\n",
      "\n",
      "Fold 5 - Train Accuracy: 0.9851, Train Loss: 0.0702, Test Accuracy: 0.9850, Test Loss: 0.0724\n",
      "Fold 5 - Confusion Matrix:\n",
      "[[14113   249]\n",
      " [  228 17203]]\n",
      "\n",
      "\n",
      "Aggregated Metrics:\n",
      "Average Train Accuracy: 0.9851\n",
      "Average Train Loss: 0.0704\n",
      "Average Test Accuracy: 0.9851\n",
      "Average Test Loss: 0.0727\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[70116  1296]\n",
      " [ 1075 86481]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.98      0.98     14362\n",
      "           2       0.99      0.99      0.99     17431\n",
      "\n",
      "    accuracy                           0.98     31793\n",
      "   macro avg       0.98      0.98      0.98     31793\n",
      "weighted avg       0.98      0.98      0.98     31793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, log_loss, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "accuracies_train = []\n",
    "losses_train = []\n",
    "dt_accuracies_test = []\n",
    "losses_test = []\n",
    "confusion_matrices = [] \n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = (\n",
    "        folds_data[i]['X_train'],\n",
    "        folds_data[i]['X_test'],\n",
    "        folds_data[i]['y_train'],\n",
    "        folds_data[i]['y_test'],\n",
    "    )\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=45, min_impurity_decrease=0.001)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Train predictions and loss\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_proba = model.predict_proba(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    loss_train = log_loss(y_train, y_train_pred_proba)\n",
    "\n",
    "    # Test predictions and loss\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    loss_test = log_loss(y_test, y_test_pred_proba)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    accuracies_train.append(accuracy_train)\n",
    "    losses_train.append(loss_train)\n",
    "    dt_accuracies_test.append(accuracy_test)\n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    print(f\"Fold {i+1} - Train Accuracy: {accuracy_train:.4f}, Train Loss: {loss_train:.4f}, Test Accuracy: {accuracy_test:.4f}, Test Loss: {loss_test:.4f}\")\n",
    "    print(f\"Fold {i+1} - Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "avg_accuracy_train = np.mean(accuracies_train)\n",
    "avg_loss_train = np.mean(losses_train)\n",
    "avg_accuracy_test = np.mean(dt_accuracies_test)\n",
    "avg_loss_test = np.mean(losses_test)\n",
    "\n",
    "print(f\"\\nAggregated Metrics:\")\n",
    "print(f\"Average Train Accuracy: {avg_accuracy_train:.4f}\")\n",
    "print(f\"Average Train Loss: {avg_loss_train:.4f}\")\n",
    "print(f\"Average Test Accuracy: {avg_accuracy_test:.4f}\")\n",
    "print(f\"Average Test Loss: {avg_loss_test:.4f}\")\n",
    "\n",
    "print(\"\\nOverall Confusion Matrix:\")\n",
    "print(sum(confusion_matrices))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error: DT\n",
    "Our model is also performing well, and with each confusion metric no less than 0.98. As this is a decision tree, a model usually prone to overfitting, we do see minimal overfitting, seeing as our train loss is higher than our test loss by 0.0023, though this is arguably a negligible gap.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to our methodology with Logistic Regression, we will implement random search for our tuning as a compromise to exhaustively searching through each hyperparameter combination. This time, we will explicitly define certain thresholds and measures. \n",
    "\n",
    "Our previous two hyperparameters, max_depth and minimum_impurity_decrease, will now range fom 30-60 and 0.001 to 0.1 respectively, adding variability to our parameters despite minimal signs of overfitting. We will allow the min_samples_leaf to enforce generalization or allow leaf nodes with one sample. \n",
    "\n",
    "Of note, we will add cost-complexity pruning as a form of regularizaton for our decision trees. We will also be exploring both gini and entropy as criteria, as the former minimizes chances of misclassification while the latter measures information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error: DT\n",
    "Our model is also performing well, and with each confusion metric no less than 0.98. As this is a decision tree, a model usually prone to overfitting, we do see minimal overfitting, seeing as our train loss is higher than our test loss by 0.0023, though this is arguably a negligible gap.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 35\u001b[0m\n\u001b[0;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m)\n\u001b[0;32m     32\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     33\u001b[0m     model, p_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m\n\u001b[0;32m     34\u001b[0m )\n\u001b[1;32m---> 35\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m best_params_list\u001b[38;5;241m.\u001b[39mappend(random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     39\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy_score(y_test, random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "p_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [30, 45, 50, 60],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_impurity_decrease\": [0.001, 0.005, 0.01], ## pre-pruning\n",
    "    \"ccp_alpha\": np.logspace(-4, 0, 10) ## post-pruning\n",
    "}\n",
    "\n",
    "best_params_list = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "losses = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = (\n",
    "        folds_data[i]['X_train'],\n",
    "        folds_data[i]['X_test'],\n",
    "        folds_data[i]['y_train'],\n",
    "        folds_data[i]['y_test'],\n",
    "    )\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=45)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, p_grid, n_iter=20, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1, random_state=45\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params_list.append(random_search.best_params_)\n",
    "\n",
    "    accuracies.append(accuracy_score(y_test, random_search.best_estimator_.predict(X_test)))\n",
    "    report = classification_report(y_test, random_search.best_estimator_.predict(X_test), output_dict=True, zero_division=0)\n",
    "    losses.append(log_loss(y_test, random_search.best_estimator_.predict_proba(X_test)))\n",
    "    precisions.append(report['macro avg']['precision'])\n",
    "    recalls.append(report['macro avg']['recall'])\n",
    "    f1_scores.append(report['macro avg']['f1-score'])\n",
    "\n",
    "    print(f\"Fold {i+1} - Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"Fold {i+1} - Accuracy: {accuracies[-1]:.4f}, Precision: {precisions[-1]:.4f}, Recall: {recalls[-1]:.4f}, F1-score: {f1_scores[-1]:.4f}, Loss: {losses[-1]:.4f}\")\n",
    "\n",
    "\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_loss = np.mean(losses)\n",
    "\n",
    "print(f\"\\nAggregated Metrics:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.4f}\")\n",
    "print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "print(\"\\nBest Parameters for each fold:\")\n",
    "for i, params in enumerate(best_params_list):\n",
    "    print(f\"Fold {i+1}: {params}\")\n",
    "\n",
    "\n",
    "best_fold_index = np.argmax(accuracies)\n",
    "best_fold_params = best_params_list[best_fold_index]\n",
    "print(\"\\nBest Performing Fold Parameters:\", best_fold_params)\n",
    "\n",
    "\n",
    "best_model = DecisionTreeClassifier(random_state=45, **best_fold_params)\n",
    "\n",
    "\n",
    "all_X_train = np.concatenate([folds_data[i]['X_train'] for i in range(5)])\n",
    "all_y_train = np.concatenate([folds_data[i]['y_train'] for i in range(5)])\n",
    "\n",
    "best_model.fit(all_X_train, all_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_preds = best_model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "\n",
    "test_preds = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "train_probs = best_model.predict_proba(X_train)\n",
    "test_probs = best_model.predict_proba(X_test)\n",
    "train_loss = log_loss(y_train, train_probs)\n",
    "test_loss = log_loss(y_test, test_probs)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_preds)  \n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=[\"Predicted Negative\", \"Predicted Positive\"], \n",
    "            yticklabels=[\"Actual Negative\", \"Actual Positive\"])\n",
    "\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(cm)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"Training Log Loss: {train_loss:.4f}\")\n",
    "print(f\"Test Log Loss: {test_loss:.4f}\")\n",
    "\n",
    "\n",
    "train_precision = precision_score(y_train, train_preds, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_preds, zero_division=0)\n",
    "\n",
    "train_recall = recall_score(y_train, train_preds, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_preds, zero_division=0)\n",
    "\n",
    "train_f1 = f1_score(y_train, train_preds, zero_division=0)\n",
    "test_f1 = f1_score(y_test, test_preds, zero_division=0)\n",
    "\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "print(f\"Training F1-score: {train_f1:.4f}\")\n",
    "print(f\"Test F1-score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Fold 1 - Train Accuracy: 0.9862, Train Loss: 0.4274, Test Accuracy: 0.9856, Test Loss: 0.4478\n",
      "Fold 1 - Confusion Matrix:\n",
      "[[14051   251]\n",
      " [  206 17286]]\n",
      "\n",
      "fold 2\n",
      "Fold 2 - Train Accuracy: 0.9854, Train Loss: 0.4311, Test Accuracy: 0.9852, Test Loss: 0.4424\n",
      "Fold 2 - Confusion Matrix:\n",
      "[[13965   221]\n",
      " [  250 17358]]\n",
      "\n",
      "fold 3\n",
      "Fold 3 - Train Accuracy: 0.9860, Train Loss: 0.4273, Test Accuracy: 0.9866, Test Loss: 0.4196\n",
      "Fold 3 - Confusion Matrix:\n",
      "[[14145   204]\n",
      " [  222 17223]]\n",
      "\n",
      "fold 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m knn_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 23\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mknn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m y_train_pred_proba \u001b[38;5;241m=\u001b[39m knn_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_train)\n\u001b[0;32m     25\u001b[0m accuracy_train \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, y_train_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:277\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    275\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    280\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py:906\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 906\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:2252\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2251\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2252\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2254\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2258\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:2480\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2478\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:1973\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1970\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:388\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m         )\n\u001b[1;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\pairwise.py:428\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    425\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    426\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[1;32m--> 428\u001b[0m xp_zero \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m distances \u001b[38;5;241m=\u001b[39m _modify_in_place_if_numpy(\n\u001b[0;32m    430\u001b[0m     xp, xp\u001b[38;5;241m.\u001b[39mmaximum, distances, xp_zero, out\u001b[38;5;241m=\u001b[39mdistances\n\u001b[0;32m    431\u001b[0m )\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_array_api.py:401\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.asarray\u001b[1;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m--> 401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21masarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     _check_device_cpu(device)\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# Support copy in NumPy namespace\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#initial k value, optimal value will be determined later\n",
    "k = 5\n",
    "\n",
    "accuracies_train = []\n",
    "losses_train = []\n",
    "knn_accuracies_test = []\n",
    "losses_test = []\n",
    "confusion_matrices = [] \n",
    "\n",
    "for i, fold in enumerate(folds_data):\n",
    "    print(f\"fold {i+1}\")\n",
    "\n",
    "    X_train = fold['X_train']\n",
    "    y_train = fold['y_train']\n",
    "    X_test = fold['X_test']\n",
    "    y_test = fold['y_test']\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "\n",
    "    y_train_pred = knn_model.predict(X_train)\n",
    "    y_train_pred_proba = knn_model.predict_proba(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    loss_train = log_loss(y_train, y_train_pred_proba)\n",
    "\n",
    "    y_test_pred = knn_model.predict(X_test)\n",
    "    y_test_pred_proba = knn_model.predict_proba(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    loss_test = log_loss(y_test, y_test_pred_proba)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    accuracies_train.append(accuracy_train)\n",
    "    losses_train.append(loss_train)\n",
    "    knn_accuracies_test.append(accuracy_test)\n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    ## perf metrics\n",
    "    print(f\"Fold {i+1} - Train Accuracy: {accuracy_train:.4f}, Train Loss: {loss_train:.4f}, Test Accuracy: {accuracy_test:.4f}, Test Loss: {loss_test:.4f}\")\n",
    "    print(f\"Fold {i+1} - Confusion Matrix:\\n{cm}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Optimal K value (hpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k: 5\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': range(1, 31)} \n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(weights='distance'), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best k:\", grid_search.best_params_['n_neighbors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14135   227]\n",
      " [  233 17198]]\n",
      "acc:  0.9855314062844023\n"
     ]
    }
   ],
   "source": [
    "knn_cm = confusion_matrix(y_test, y_pred)\n",
    "print(knn_cm)\n",
    "knn_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"acc: \", knn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" LR Accuracies:\", lr_accuracies_test)\n",
    "print(\" DT Accuracies:\", dt_accuracies_test)\n",
    "print(\" KNN Accuracies:\", knn_accuracies_test)\n",
    "\n",
    "dt_accuracies_test = np.array(dt_accuracies_test)\n",
    "knn_accuracies_test = np.array(knn_accuracies_test) \n",
    "rf_accuracies_test = np.array(lr_accuracies_test) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
