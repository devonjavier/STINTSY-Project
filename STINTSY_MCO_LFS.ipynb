{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction ##\n",
    "\n",
    "In this notebook, the dataset to be processed is the Labor Force Survey conducted April 2016 and retrieved through Philippine Statistics Authority database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing LFS PUF April 2016.CSV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Information, Pre-Processing, and Cleaning</h1>\n",
    "\n",
    "Let's get an overview of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Of interest to us, there are:\n",
    "<ul><li>1 contains float values, </li>\n",
    "<li>14 contain integer values, and </li>\n",
    "<li><b>35 are object values</b>.</li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates here, and therefore no cleaning need follow in this regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to contain null values in the form of whitespaces. Let's count those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null = lfs_data.apply(lambda col: col.str.isspace().sum() if col.dtype == 'object' else 0)\n",
    "\n",
    "print(\"Number Empty Cells:\")\n",
    "print(has_null[has_null > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And standardize, replacing these whitespace values with NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", np.nan, regex=True, inplace=True)\n",
    "nan_counts_per_column = lfs_data.isna().sum()\n",
    "print(nan_counts_per_column[nan_counts_per_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these are NaN, let's return to the data types, and find if our object columns from earlier are convertible to integers (or float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_convertible_columns = []\n",
    "\n",
    "for col in lfs_data.columns:\n",
    "    if lfs_data[col].dtypes == 'object':  \n",
    "        try:\n",
    "            float_vals = lfs_data[col].dropna().astype(float)\n",
    "            if (float_vals % 1 == 0).all():\n",
    "                int_convertible_columns.append(col)\n",
    "        except ValueError:\n",
    "            pass \n",
    "\n",
    "print(\"Safely convertable to int:\")\n",
    "print(int_convertible_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And convert to pd.Int32Dtype, as to handle potential NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'PUFC06_MSTAT', 'PUFC08_CURSCH', 'PUFC09_GRADTECH', 'PUFC10_CONWR', 'PUFC11_WORK', \n",
    "    'PUFC12_JOB', 'PUFC14_PROCC', 'PUFC16_PKB', 'PUFC17_NATEM', 'PUFC18_PNWHRS', \n",
    "    'PUFC19_PHOURS', 'PUFC20_PWMORE', 'PUFC21_PLADDW', 'PUFC22_PFWRK', 'PUFC23_PCLASS', \n",
    "    'PUFC24_PBASIS', 'PUFC25_PBASIC', 'PUFC26_OJOB', 'PUFC27_NJOBS', 'PUFC28_THOURS', \n",
    "    'PUFC29_WWM48H', 'PUFC30_LOOKW', 'PUFC31_FLWRK', 'PUFC32_JOBSM', 'PUFC33_WEEKS', \n",
    "    'PUFC34_WYNOT', 'PUFC35_LTLOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING', 'PUFC38_PREVJOB', \n",
    "    'PUFC40_POCC', 'PUFC41_WQTR', 'PUFC43_QKB', 'PUFNEWEMPSTAT'\n",
    "]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in lfs_data.columns: \n",
    "        try:\n",
    "            lfs_data[col] = lfs_data[col].astype(pd.Int64Dtype())\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert column {col} to nullable integer due to invalid values.\")\n",
    "\n",
    "print(\"Conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's also apply the unique() function to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Considering our dataset has 18,000 entries, features with particularly low numbers stand out as questions that have clear, defined choices. Reviewing the [questionnaire](https://psada.psa.gov.ph/catalog/67/download/537), we find that certain questions ask the participant to specify beyond prespecified choices.\n",
    "\n",
    "This column possibly contains \"010,\" which is obviously not an integer. We ensure this column is a string, and check for values not specified in the questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data['PUFC07_GRADE'] = lfs_data['PUFC07_GRADE']\n",
    "valid_codes = [\n",
    "    0, 10,  # No Grade, Preschool\n",
    "    210, 220, 230, 240, 250, 260, 280,  # Elementary\n",
    "    310, 320, 330, 340, 350,  # High School\n",
    "    410, 420,  # Post Secondary; If Graduate Specify\n",
    "    810, 820, 830, 840,  # College; If Graduate Specify\n",
    "    900,  # Post Baccalaureate\n",
    "    np.nan\n",
    "]\n",
    "invalid_rows = lfs_data[~(lfs_data['PUFC07_GRADE'].isin(valid_codes))]\n",
    "\n",
    "unique_invalid_values = invalid_rows['PUFC07_GRADE'].unique()\n",
    "print(unique_invalid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values 5XX 6XX are not detailed in the questionnaire. As it instructs the participant to specify whether they graduated from post secondary or college, we'll create a new data point to encapsulate these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[~lfs_data['PUFC07_GRADE'].isin(valid_codes), 'PUFC07_GRADE'] = 700\n",
    "print(lfs_data['PUFC07_GRADE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = lfs_data.corr()\n",
    "\n",
    "strong_correlations = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)): \n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if (0.5 < corr_value < 1) or (-1 < corr_value < -0.5):\n",
    "            strong_correlations.append((\n",
    "                corr_matrix.index[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_value\n",
    "            ))\n",
    "\n",
    "strong_correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(\"Strong correlations (|corr| > 0.5 and |corr| < 1):\")\n",
    "for var1, var2, corr in strong_correlations:\n",
    "    print(f\"{var1} â€” {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LFSDataset(Dataset):\n",
    "    def __init__(self, features, labels, missing_value=-1):\n",
    "        self.features = features.values.astype(np.float32)\n",
    "        \n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) <= 2 and 0 in unique_labels and 1 in unique_labels:\n",
    "            self.labels = labels.values.astype(np.float32)\n",
    "        else:\n",
    "            min_label = labels.min()\n",
    "            self.labels = (labels.values != min_label).astype(np.float32)\n",
    "            print(f\"Normalized target values from {unique_labels} to [0, 1]\")\n",
    "        \n",
    "        self.missing_value = missing_value\n",
    "        self.mask = (self.features != missing_value).astype(np.float32)\n",
    "        self.features = np.where(self.features == missing_value, 0, self.features)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'mask': self.mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "class MaskedLogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MaskedLogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, features, mask):\n",
    "        masked_features = features * mask\n",
    "        output = self.linear(masked_features)\n",
    "        return torch.sigmoid(output)\n",
    "\n",
    "def prepare_data(lfs_data, target_col='PUFC11_WORK', feature_cols=None, test_size=0.2, missing_value=-1):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [\n",
    "            'PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', \n",
    "            'PUFC07_GRADE', 'PUFC08_CURSCH', \n",
    "            'PUFC38_PREVJOB', 'PUFC31_FLWRK',\n",
    "            'PUFC30_LOOKW', 'PUFC34_WYNOT'\n",
    "        ]\n",
    "    \n",
    "    available_features = [col for col in feature_cols if col in lfs_data.columns]\n",
    "    if not available_features:\n",
    "        raise ValueError(\"None of the specified features are in the dataset\")\n",
    "    \n",
    "    if target_col not in lfs_data.columns:\n",
    "        raise ValueError(f\"Target column {target_col} not found in dataset\")\n",
    "    \n",
    "    mask = lfs_data[target_col].notna()\n",
    "    filtered_data = lfs_data.loc[mask, available_features + [target_col]]\n",
    "    \n",
    "    print(f\"Target variable: {target_col}\")\n",
    "    print(f\"Unique values in target: {sorted(filtered_data[target_col].unique())}\")\n",
    "    \n",
    "    X = filtered_data[available_features]\n",
    "    y = filtered_data[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_missing_mask = X_train.isna()\n",
    "    test_missing_mask = X_test.isna()\n",
    "    \n",
    "    X_train_filled = X_train.fillna(0)\n",
    "    X_test_filled = X_test.fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train_filled),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test_filled),\n",
    "        columns=X_test.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    \n",
    "    X_train_scaled[train_missing_mask] = missing_value\n",
    "    X_test_scaled[test_missing_mask] = missing_value\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train_scaled,\n",
    "        'X_test': X_test_scaled,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'feature_names': available_features,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "def train_model(data_dict, learning_rate=0.01, batch_size=64, num_epochs=10, \n",
    "                scheduler_step_size=3, scheduler_gamma=0.5, missing_value=-1):\n",
    "    train_dataset = LFSDataset(data_dict['X_train'], data_dict['y_train'], missing_value)\n",
    "    test_dataset = LFSDataset(data_dict['X_test'], data_dict['y_test'], missing_value)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    input_dim = data_dict['X_train'].shape[1]\n",
    "    model = MaskedLogisticRegression(input_dim)\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            features = batch['features']\n",
    "            mask = batch['mask']\n",
    "            labels = batch['labels'].view(-1, 1)\n",
    "            \n",
    "            outputs = model(features, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                features = batch['features']\n",
    "                mask = batch['mask']\n",
    "                labels = batch['labels'].view(-1, 1)\n",
    "                \n",
    "                outputs = model(features, mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                predicted = (outputs >= 0.5).float()\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = correct / total\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['test_loss'].append(avg_test_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['test_accuracy'].append(test_accuracy)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.4f}, '\n",
    "              f'Test Acc: {test_accuracy:.4f}, '\n",
    "              f'LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'feature_names': data_dict['feature_names']\n",
    "    }\n",
    "\n",
    "def analyze_model(result_dict):\n",
    "    history = result_dict['history']\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
    "    plt.plot(epochs, history['test_loss'], 'r-', label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_accuracy'], 'b-', label='Train Acc')\n",
    "    plt.plot(epochs, history['test_accuracy'], 'r-', label='Val Acc')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    model = result_dict['model']\n",
    "    feature_names = result_dict['feature_names']\n",
    "    \n",
    "    weights = model.linear.weight.data.numpy().flatten()\n",
    "    bias = model.linear.bias.data.numpy()[0]\n",
    "    \n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': weights\n",
    "    })\n",
    "    \n",
    "    coefficients = coefficients.reindex(coefficients['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "    \n",
    "    print(f\"\\nBias: {bias:.4f}\")\n",
    "    print(coefficients)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(coefficients['Feature'], coefficients['Coefficient'].abs(), color='skyblue')\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def predict_employment_status(lfs_data, result_dict, target_normalization=None, missing_value=-1):\n",
    "    model = result_dict['model']\n",
    "    feature_names = result_dict['feature_names']\n",
    "    \n",
    "    X = lfs_data[feature_names]\n",
    "    mask = (X != missing_value).astype(np.float32)\n",
    "    X = X.replace(missing_value, 0).astype(np.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.tensor(X.values), torch.tensor(mask.values))\n",
    "        binary_predictions = (predictions >= 0.5).float().numpy().flatten()\n",
    "    \n",
    "    if target_normalization is not None and 'original_values' in target_normalization:\n",
    "        original_values = target_normalization['original_values']\n",
    "        if len(original_values) == 2:\n",
    "            value_map = {0: min(original_values), 1: max(original_values)}\n",
    "            return pd.Series([value_map[int(p)] for p in binary_predictions], index=X.index)\n",
    "    \n",
    "    return pd.Series(binary_predictions, index=X.index)\n",
    "\n",
    "def run_employment_prediction(lfs_data, target_col='PUFC11_WORK'):\n",
    "    print(\"Preparing data...\")\n",
    "    data_dict = prepare_data(lfs_data, target_col=target_col)\n",
    "    \n",
    "    print(f\"Training on {len(data_dict['X_train'])} samples with {len(data_dict['feature_names'])} features...\")\n",
    "    print(f\"Features: {data_dict['feature_names']}\")\n",
    "    \n",
    "    original_values = sorted(lfs_data[target_col].dropna().unique())\n",
    "    target_normalization = {'original_values': original_values}\n",
    "    print(f\"Original target values: {original_values}\")\n",
    "    \n",
    "    result_dict = train_model(\n",
    "        data_dict,\n",
    "        learning_rate=0.01,\n",
    "        batch_size=128,\n",
    "        num_epochs=10,\n",
    "        scheduler_step_size=3,\n",
    "        scheduler_gamma=0.5\n",
    "    )\n",
    "    \n",
    "    result_dict['target_normalization'] = target_normalization\n",
    "    \n",
    "    print(\"\\nModel training complete!\")\n",
    "    analyze_model(result_dict)\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# result_dict = run_employment_prediction(lfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = run_employment_prediction(lfs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIP: <To Annotate LR and push NN>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
